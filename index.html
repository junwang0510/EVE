<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EVE</title>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="static/images/favicon.ico" type="image/x-icon">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<!-- Authors, Affiliations, Links -->
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <img src="static/images/EVE_logo.png" alt="EVE logo" width="50">
            EVE: Enabling Anyone to Train Robots using Augmented Reality<br>
            <span style="font-size: 0.6em;">UIST 2024</span>
          </h1>

          <div class="is-size-5 publication-authors">
            <div class="author-images">
              <span class="author-block">
                <img src="static/images/authors/jun.jpg" alt="Jun Wang" class="author-image">
              </span>
              <span class="author-block">
                <img src="static/images/authors/chang.jpg" alt="Chun-Cheng Chang" class="author-image">
              </span>
              <span class="author-block">
                <img src="static/images/authors/jiafei.jpg" alt="Jiafei Duan" class="author-image">
              </span>
              <span class="author-block">
                <img src="static/images/authors/dieter.jpg" alt="Dieter Fox" class="author-image">
              </span>
              <span class="author-block">
                <img src="static/images/authors/ranjay.jpg" alt="Ranjay Krishna" class="author-image">
              </span>
            </div>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://junwang0510.github.io/">Jun Wang<sup style="color: #555; font-size: 0.65em;">&spades;</sup></a>
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/chun-cheng-chang-28b49a223/">Chun-Cheng Chang<sup style="color: #555; font-size: 0.65em;">&spades;*</sup></a>
            </span>
            <span class="author-block">
              <a href="https://duanjiafei.com/">Jiafei Duan<sup style="color: #555; font-size: 0.65em;">&spades;*</sup></a>
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox<sup style="color: #555; font-size: 0.65em;">&spades;&diams;</sup></a>
            </span>
            <span class="author-block">
              <a href="https://www.ranjaykrishna.com/index.html">Ranjay Krishna<sup style="color: #555; font-size: 0.65em;">&spades;&clubs;</sup></a>
            </span>
          </div>

          <div class="is-size-5 publication-affiliations">
            <span class="affiliation-block"><sup>&spades;</sup>University of Washington</span>
            <span class="affiliation-block"><sup>&diams;</sup>NVIDIA</span>
            <span class="affiliation-block"><sup>&clubs;</sup>Allen Institute for AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2404.06089"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.06089"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/8f5J8AVTxLM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/junwang0510"
                   class="external-link button is-normal is-rounded is-dark" style="pointer-events: none; cursor: default;">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <h2 class="subtitle has-text-centered">
      <i class="fas fa-mobile-alt"></i>&nbsp;EVE is an <strong>iOS app</strong> that enables <strong>everyday users</strong> to train robots using<br>intuitive <strong>augmented reality visualizations</strong>, without needing a real robot.
    </h2>
      <video id="teaser" autoplay muted loop playsinline height="100%" style="margin-bottom: 50px;">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The increasing affordability of robot hardware is accelerating the integration of robots into everyday activities. However, training a robot to automate a task requires expensive trajectory data where a trained human annotator moves a physical robot to train it. Consequently, only those with access to robots produce demonstrations to train robots.
          </p>
          <p>
            In this work, we remove this restriction with EVE, an iOS app that enables everyday users to train robots using intuitive augmented reality visualizations, without needing a physical robot. With EVE, users can collect demonstrations by specifying waypoints with their hands, visually inspecting the environment for obstacles, modifying existing waypoints, and verifying collected trajectories.
          </p>
          <p>
            In a user study ($N=14$, $D=30$) consisting of three common tabletop tasks, EVE outperformed three state-of-the-art interfaces in success rate and was comparable to kinesthetic teaching—physically moving a physical robot—in completion time, usability, motion intent communication, enjoyment, and preference ($mean_{p}=0.30$). EVE allows users to train robots for personalized tasks, such as sorting desk supplies, organizing ingredients, or setting up board games. We conclude by enumerating limitations and design considerations for future AR-based demonstration collection systems for robotics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Formative Study -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Formative User Study</h2>
        <div class="content has-text-justified">
          <p>
            To understand the opportunities and challenges of trajectory collection, we conducted a formative study with $10$ participants with varying experience in robotics, using state-of-the-art collection interfaces (kinesthetic teaching, teleoperation with a VR controller, <a href="https://arxiv.org/abs/2306.13818">AR2-D2</a>) and the initial prototype of EVE with three different AR visualizations (AR Kinesthetic Teaching, Path History, Invisible Robot).
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-arkt">
          <div class="video-title">Kinesthetic Teaching</div>
          <video poster="" id="kt" autoplay controls muted loop playsinline>
            <source src="./static/videos/kt.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-arkt">
          <div class="video-title">Teleoperation</div>
          <video poster="" id="teleop" autoplay controls muted loop playsinline>
            <source src="./static/videos/teleop.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-arkt">
          <div class="video-title">AR2-D2</div>
          <video poster="" id="ar2d2" autoplay controls muted loop playsinline>
            <source src="./static/videos/ar2d2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-arkt">
          <div class="video-title">AR Kinesthetic Teaching</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/arkt.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-path">
          <div class="video-title">Path History</div>
          <video poster="" id="path" autoplay controls muted loop playsinline>
            <source src="./static/videos/path_history.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-invbot">
          <div class="video-title">Invisible Robot</div>
          <video poster="" id="invbot" autoplay controls muted loop playsinline>
            <source src="./static/videos/invisible_robot.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="static/images/formative/comments.png" alt="user comments" style="margin-bottom: 15px;">
      <h2 class="subtitle has-text-justified small-caption">
        User comments about the six demonstration collection methods used in the formative study.
      </h2>
      <img src="static/images/formative/formative_results.png" alt="formative study results" width="70%">
      <h2 class="subtitle has-text-justified small-caption" style="margin-bottom: 25px;">
        The mean and standard deviation of usability (SUS: 1-100), motion intent communication (ranking: 1-4), user enjoyment (ranking: 1-4), and user preference (ranking: 1-4) are provided. Statistical significance is indicated by $\:\hat{}\:$ for $p \lt 0.05$.
      </h2>
    </div>
  </div>
  <div class="container is-max-desktop" style="margin-bottom: 50px;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            In addition, we distilled the challenges users faced with the current AR visualizations into the following six based on the semi-structured interviews:
          </p>
          <ol>
            <li>
              <strong>Ambiguous spatial position of the hand and the robot:</strong> The lack of depth perception made it challenging for users to accurately gauge the relative positions of their hands and the AR robot.
            </li>
            <li>
              <strong>Lack of knowledge of joint constraints:</strong> A lack of information about the joint limits, coupled with the lack of depth perception via the iPad screen, causes the robot to move unexpectedly when the specified point with the hand is out of the joint limit.
            </li>
            <li>
              <strong>Imprecise trajectory visualization:</strong> The path history visualization displays a straight green line between the robot's end effector coordinate and the user's hand coordinate.
            </li>
            <li>
              <strong>Absence of feedback regarding the collection efficacy:</strong> The lack of collision detection prevented the participants from verifying whether the collected trajectory was feasible.
            </li>
            <li>
              <strong>Obstructive robot design:</strong> The AR robot's 1:1 scale correspondence with the physical Franka Panda robot frequently resulted in the occlusion of relevant objects within the scene.
            </li>
            <li>
              <strong>Inconsistent hand tracking:</strong> Inaccuracies and latency in the hand tracking system employed in the AR environment.
            </li>
          </ol>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Evaluation Study -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Evaluation User Study</h2>
        <div class="content has-text-justified">
          <p>
            Informed by formative study findings and our own experiences using EVE, we upgraded EVE's prototype with seven additional system changes to address the usability challenges.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Evaluation Study Interfaces -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-reselection">
          <div class="video-title">Robot Instantiation Reselection</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/reselect.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-replay">
          <div class="video-title">Trajectory Replay</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/replay.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-cam">
          <div class="video-title">Dynamic Camera View</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/cam.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-handpos">
          <div class="video-title">Hand Position Projection</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/handpos.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-joint">
          <div class="video-title">Joint Constraints Signifier</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/joint.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-traj">
          <div class="video-title">Realistic Trajectory</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/traj.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-gripper">
          <div class="video-title">Accurate Gripper Control</div>
          <video poster="" id="arkt" autoplay controls muted loop playsinline>
            <source src="./static/videos/gripper.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Evaluation Study Tasks & Results-->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            We conducted a user study to evaluate the effectiveness of EVE compared to baseline interfaces for three common tabletop tasks. We include the task setups and the real-world policy evaluation using data collected with EVE below.
          </p>
        </div>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="columns is-centered" style="margin-top: 30px;">
      <div class="column is-half has-text-centered">
        <div class="select is-rounded">
          <select id="task-select" onchange="updateTaskMedia()">
            <option value="switch">🔌 Toggle Switch</option>
            <option value="sort">🧺 Sort Food</option>
            <option value="sweep">🧽 Sweep Table</option>
          </select>
        </div>
    </div>
  </div>
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-one-third has-text-centered">
        <img id="task-image" src="static/images/evaluation/switch.png" alt="Toggle Switch" class="task-image">
      </div>
      <div class="column is-one-third has-text-centered">
        <video id="task-video1" controls class="task-video" autoplay controls muted loop playsinline>
          <source src="static/videos/switch.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div><div class="container is-max-desktop" style="margin-top: 30px;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <p>
            Success rates and remaining time for each task were recorded for all interfaces. Upon completing the task collection with all interfaces, participants filled out the SUS survey and a form ranking motion intent communication, user enjoyment, and overall preference for the interfaces. We aimed to measure $10$ collection attempts for each task.
          </p>
        </div>
      </div>
    </div>
  </div>
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered">
        <div class="column is-half">
          <img src="static/images/evaluation/success.png" alt="success rate">
          <!-- <h2 class="subtitle has-text-justified small-caption">
            The mean task success rate (%) for all interfaces in the evaluation user study, which included three tasks with $10$ trials each, indicates that EVE achieved the highest success rate across all tasks.
          </h2> -->
        </div>
        <div class="column is-half">
          <img src="static/images/evaluation/time.png" alt="remaining time">
          <!-- <h2 class="subtitle has-text-justified small-caption">
            The mean and the standard deviation of the remaining time (sec) for completing one demonstration for each task. EVE performed comparably to kinesthetic teaching, with an average difference of $5.1$ seconds across all tasks.
          </h2> -->
        </div>
      </div>
      <div class="columns is-centered" style="margin-top: 30px;">
        <div class="column is-half">
          <img src="static/images/evaluation/eval_1.png" alt="eval_1">
        </div>
        <div class="column is-half">
          <img src="static/images/evaluation/eval_2.png" alt="eval_2">
        </div>
      </div>
      <!-- <h2 class="subtitle has-text-justified small-caption">
        EVE performed comparably to kinesthetic teaching in usability, motion intent communication, user enjoyment, and user preference. The mean and standard deviation of all measurements are shown. Usability is rated on a scale from 0-100, with higher scores indicating better usability. Motion intent communication, user enjoyment, and user preference are ranked from 1-4, with lower ranks indicating better performance. Statistical significance is indicated by $*$ for $p \lt 0.05$ compared to EVE.
      </h2> -->
    </div>
  </div>
</section>

<!-- Policy Evaluation: AR2-D2 vs. EVE -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Policy Evaluation: AR2-D2 vs. EVE</h2>
        <div class="content has-text-justified">
          <p>
            We trained policies with <a href="https://peract.github.io/">Perceiver-Actor (PerAct)</a>, using $6$ demonstrations over $30,000$ iterations for each interface. On $30$ task rollouts for the toggle switch task, the policy trained with EVE-collected data achieved a $10$% higher accuracy compared to that trained with AR2-D2-collected data.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-three-quarters has-text-centered">
        <div class="content">
          <div class="columns is-multiline is-centered">
            <div class="column is-half">
              <div class="video-title">AR2-D2 RGB-D</div>
              <video controls class="task-video" autoplay controls muted loop playsinline>
                <source src="./static/videos/ar2d2_rgbd.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <div class="video-title">AR2-D2 Evaluation</div>
              <video controls class="task-video" autoplay controls muted loop playsinline>
                <source src="./static/videos/ar2d2_eval.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <div class="video-title">EVE RGB-D</div>
              <video controls class="task-video" autoplay controls muted loop playsinline>
                <source src="./static/videos/eve_rgbd.mp4" type="video/mp4">
              </video>
            </div>
            <div class="column is-half">
              <div class="video-title">EVE Evaluation</div>
              <video controls class="task-video" autoplay controls muted loop playsinline>
                <source src="./static/videos/eve_eval.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Credits -->
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>, modified by <a href="https://junwang0510.github.io/">Jun Wang</a>.
      </p>
    </div>
  </div>
</footer>
</body>
</html>
